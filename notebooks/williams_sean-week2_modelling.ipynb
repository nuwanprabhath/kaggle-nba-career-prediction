{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd04699-6cd6-4318-84aa-6fe650869df2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Advanced Data Science for Innovation - Assignment 1**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec16c8e7-22da-4fbd-b12f-637bd4883767",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NBA Career Prediction: Predict 5-Year Longevity for NBA Rookies\n",
    "**Student Name:** Sean Williams\n",
    "\n",
    "**Team Name:** Group 1\n",
    "* Nuwan Munasinghe\n",
    "* Wenying Wu\n",
    "* Nathan Fragar\n",
    "* Sean Williams\n",
    "* Carol Myhill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3f8ebf-d8d9-49df-bc95-8d6d08ced876",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd90ef7b-9ab4-436f-beb3-0127d7e25364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from importlib.machinery import SourceFileLoader\n",
    "dataprep = SourceFileLoader('sets', '../src/data/prepare.py').load_module()\n",
    "sets = SourceFileLoader('sets', '../src/data/sets.py').load_module()\n",
    "base = SourceFileLoader('base', '../src/models/null.py').load_module()\n",
    "from IPython.display import display\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "import joblib as job\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a9d51fd-7a99-46a2-9670-1d6172969baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_base(y_train_preds, y_train, y_val_preds, y_val, f1_average='weighted'):\n",
    "    name = 'Base'\n",
    "    model_scores = []\n",
    "    t_acc = accuracy_score(y_train, y_train_preds)\n",
    "    t_prec = precision_score(y_train, y_train_preds)\n",
    "    t_rec = recall_score(y_train, y_train_preds)\n",
    "    t_f1 = f1_score(y_train, y_train_preds, average=f1_average)\n",
    "    #t_auc = roc_auc_score(y_t, clf.predict_proba(X_t)[:, 1])\n",
    "    v_acc = accuracy_score(y_val, y_val_preds)\n",
    "    v_prec = precision_score(y_val, y_val_preds)\n",
    "    v_rec = recall_score(y_val, y_val_preds)\n",
    "    v_f1 = f1_score(y_val, y_val_preds, average=f1_average)\n",
    "    #v_auc = roc_auc_score(y_v, clf.predict_proba(X_v)[:, 1])\n",
    "    model_scores.append([name, t_acc, t_prec, t_rec, t_f1, v_acc, v_prec, v_rec, v_f1])\n",
    "    df_model_scores = pd.DataFrame (model_scores, columns = ['model','t_accuracy','t_precision','t_recall','t_F1','v_accuracy','v_precision','v_recall','v_F1'])\n",
    "    display(df_model_scores)\n",
    "    \n",
    "def fit_score_models(models, X_t, y_t, X_v, y_v, dump_model=\"NO\"):\n",
    "    model_scores = []\n",
    "    best_acc = 0\n",
    "    i = 0\n",
    "    for name, model in models.items():\n",
    "        i = i+1;\n",
    "        clf = model\n",
    "        if dump_model == \"YES\":\n",
    "            job.dump(clf, \"../models/williams_sean-week2_\" + name + \".joblib\", compress=3)\n",
    "        clf.fit(X_t, y_t)\n",
    "        t_preds = clf.predict(X_t)\n",
    "        t_acc = accuracy_score(y_t, t_preds)\n",
    "        if i == 1:\n",
    "            best_acc = t_acc\n",
    "            best_clf = clf\n",
    "        else:\n",
    "            if t_acc > best_acc:\n",
    "                best_acc = t_acc\n",
    "                best_clf = clf            \n",
    "        t_prec = precision_score(y_t, t_preds)\n",
    "        t_rec = recall_score(y_t, t_preds)\n",
    "        t_f1 = f1_score(y_t, t_preds)\n",
    "        t_auc = roc_auc_score(y_t, clf.predict_proba(X_t)[:, 1])\n",
    "        v_preds = clf.predict(X_v)\n",
    "        v_acc = accuracy_score(y_v, v_preds)\n",
    "        v_prec = precision_score(y_v, v_preds)\n",
    "        v_rec = recall_score(y_v, v_preds)\n",
    "        v_f1 = f1_score(y_v, v_preds)\n",
    "        v_auc = roc_auc_score(y_v, clf.predict_proba(X_v)[:, 1])\n",
    "        model_scores.append([name, t_acc, t_prec, t_rec, t_f1, t_auc, v_acc, v_prec, v_rec, v_f1, v_auc])\n",
    "    df_model_scores = pd.DataFrame (model_scores, columns = ['model','t_accuracy','t_precision','t_recall','t_F1','t_auc','v_accuracy','v_precision','v_recall','v_F1','v_auc'])\n",
    "    display(df_model_scores)\n",
    "    return best_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5f3d40-c6f1-405c-96e8-b538f341c9a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f6eb5e-bff4-4c90-bdfa-53a650cd47ad",
   "metadata": {},
   "source": [
    "**<u>Load saved data sets</u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "043bc057-687f-4721-be09-3b3252fe4371",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = sets.load_sets(path='../data/processed/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbb25ba-0eaa-45ac-a0df-ec0e2ba9bea6",
   "metadata": {},
   "source": [
    "**<u>Assess Baseline of Train and Validation datasets</u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a48d9f-82c1-40ff-adc2-ded215493741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>t_accuracy</th>\n",
       "      <th>t_precision</th>\n",
       "      <th>t_recall</th>\n",
       "      <th>t_F1</th>\n",
       "      <th>v_accuracy</th>\n",
       "      <th>v_precision</th>\n",
       "      <th>v_recall</th>\n",
       "      <th>v_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.833594</td>\n",
       "      <td>0.833594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.757942</td>\n",
       "      <td>0.83375</td>\n",
       "      <td>0.83375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.758161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  t_accuracy  t_precision  t_recall      t_F1  v_accuracy  v_precision  \\\n",
       "0  Base    0.833594     0.833594       1.0  0.757942     0.83375      0.83375   \n",
       "\n",
       "   v_recall      v_F1  \n",
       "0       1.0  0.758161  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = base.NullModel(target_type=\"classification\")\n",
    "y_base_train_preds = base_model.fit_predict(y_train)\n",
    "y_base_val_preds = base_model.fit_predict(y_val)\n",
    "score_base(y_base_train_preds, y_train, y_base_val_preds, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5198c5-8e12-449c-86a3-f944feeb0d0a",
   "metadata": {},
   "source": [
    "---\n",
    "**<u>Train various models with default parameters to determine which model is the most performant</u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bacc7ccc-956c-47c5-adac-b6ab405e46a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:19:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>t_accuracy</th>\n",
       "      <th>t_precision</th>\n",
       "      <th>t_recall</th>\n",
       "      <th>t_F1</th>\n",
       "      <th>t_auc</th>\n",
       "      <th>v_accuracy</th>\n",
       "      <th>v_precision</th>\n",
       "      <th>v_recall</th>\n",
       "      <th>v_F1</th>\n",
       "      <th>v_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.833906</td>\n",
       "      <td>0.835638</td>\n",
       "      <td>0.996813</td>\n",
       "      <td>0.909138</td>\n",
       "      <td>0.706177</td>\n",
       "      <td>0.833125</td>\n",
       "      <td>0.834903</td>\n",
       "      <td>0.997001</td>\n",
       "      <td>0.908780</td>\n",
       "      <td>0.699612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Euclidian</td>\n",
       "      <td>0.848594</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>0.975633</td>\n",
       "      <td>0.914843</td>\n",
       "      <td>0.850319</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.843627</td>\n",
       "      <td>0.962519</td>\n",
       "      <td>0.899160</td>\n",
       "      <td>0.596633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN Manhattan</td>\n",
       "      <td>0.852344</td>\n",
       "      <td>0.864134</td>\n",
       "      <td>0.976382</td>\n",
       "      <td>0.916835</td>\n",
       "      <td>0.856547</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>0.844577</td>\n",
       "      <td>0.957271</td>\n",
       "      <td>0.897400</td>\n",
       "      <td>0.588099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>0.974429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987049</td>\n",
       "      <td>0.999054</td>\n",
       "      <td>0.815625</td>\n",
       "      <td>0.836682</td>\n",
       "      <td>0.967766</td>\n",
       "      <td>0.897463</td>\n",
       "      <td>0.631926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  t_accuracy  t_precision  t_recall      t_F1     t_auc  \\\n",
       "0  Logistic Regression    0.833906     0.835638  0.996813  0.909138  0.706177   \n",
       "1        KNN Euclidian    0.848594     0.861185  0.975633  0.914843  0.850319   \n",
       "2        KNN Manhattan    0.852344     0.864134  0.976382  0.916835  0.856547   \n",
       "3              XGBoost    0.978125     0.974429  1.000000  0.987049  0.999054   \n",
       "\n",
       "   v_accuracy  v_precision  v_recall      v_F1     v_auc  \n",
       "0    0.833125     0.834903  0.997001  0.908780  0.699612  \n",
       "1    0.820000     0.843627  0.962519  0.899160  0.596633  \n",
       "2    0.817500     0.844577  0.957271  0.897400  0.588099  \n",
       "3    0.815625     0.836682  0.967766  0.897463  0.631926  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_to_fit = {\"Logistic Regression\": LogisticRegression(random_state=8, solver='liblinear'),\n",
    "                 \"KNN Euclidian\": KNeighborsClassifier(metric='euclidean'),\n",
    "                 \"KNN Manhattan\": KNeighborsClassifier(metric='manhattan'),\n",
    "                 \"XGBoost\": xgb.XGBClassifier(random_state=8, use_label_encoder=False)}\n",
    "clf1 = fit_score_models (models_to_fit, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc25db77-e548-4d44-b4aa-90735a3a9105",
   "metadata": {},
   "source": [
    "*Observations:*\n",
    "* XGBoost seems to be best performer. Next steps. Tune hyperparameters to reduce overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c77cc1-48cd-4632-a23d-3da311a37cd7",
   "metadata": {},
   "source": [
    "---\n",
    "**<u>Perform a grid serach on XGBoost to determine which hyperparameters result in best performance</u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be3e8db5-79c3-486b-a1a4-510bdf527858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:21:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best: 0.835000 using {'learning_rate': 0.01, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "clf1 = xgb.XGBClassifier(use_label_encoder=False)\n",
    "n_estimators = [100, 200, 300, 400, 500]\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1]\n",
    "param_grid = dict(learning_rate=learning_rate, n_estimators=n_estimators)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=8)\n",
    "grid_search = GridSearchCV(clf1, param_grid, scoring=\"accuracy\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# Print best score and parameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4bc1a6-a02b-4374-8156-cd4fb5cca044",
   "metadata": {},
   "source": [
    "---\n",
    "**<u>Train XGBoost with best Hyperparameter and print performance metrics</u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66b90037-9925-40c0-95f2-95db62cd587f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:21:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>t_accuracy</th>\n",
       "      <th>t_precision</th>\n",
       "      <th>t_recall</th>\n",
       "      <th>t_F1</th>\n",
       "      <th>t_auc</th>\n",
       "      <th>v_accuracy</th>\n",
       "      <th>v_precision</th>\n",
       "      <th>v_recall</th>\n",
       "      <th>v_F1</th>\n",
       "      <th>v_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.855313</td>\n",
       "      <td>0.852213</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>0.920131</td>\n",
       "      <td>0.872544</td>\n",
       "      <td>0.8275</td>\n",
       "      <td>0.835234</td>\n",
       "      <td>0.988006</td>\n",
       "      <td>0.90522</td>\n",
       "      <td>0.676218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  t_accuracy  t_precision  t_recall      t_F1     t_auc  v_accuracy  \\\n",
       "0  XGBoost    0.855313     0.852213  0.999813  0.920131  0.872544      0.8275   \n",
       "\n",
       "   v_precision  v_recall     v_F1     v_auc  \n",
       "0     0.835234  0.988006  0.90522  0.676218  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_to_fit = {\"XGBoost\": xgb.XGBClassifier(random_state=8, use_label_encoder=False, learning_rate=0.01, n_estimators=300)}\n",
    "clf2 = fit_score_models (models_to_fit, X_train, y_train, X_val, y_val, \"YES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3238f18b-4e51-4dee-964d-5d43127fb1d8",
   "metadata": {},
   "source": [
    "# Kaggle Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fa8c088-dcda-4a30-acc2-4bf62c5c4c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3799 entries, 0 to 3798\n",
      "Data columns (total 19 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   GP       3799 non-null   float64\n",
      " 1   MIN      3799 non-null   float64\n",
      " 2   PTS      3799 non-null   float64\n",
      " 3   FGM      3799 non-null   float64\n",
      " 4   FGA      3799 non-null   float64\n",
      " 5   FG%      3799 non-null   float64\n",
      " 6   3P Made  3799 non-null   float64\n",
      " 7   3PA      3799 non-null   float64\n",
      " 8   3P%      3799 non-null   float64\n",
      " 9   FTM      3799 non-null   float64\n",
      " 10  FTA      3799 non-null   float64\n",
      " 11  FT%      3799 non-null   float64\n",
      " 12  OREB     3799 non-null   float64\n",
      " 13  DREB     3799 non-null   float64\n",
      " 14  REB      3799 non-null   float64\n",
      " 15  AST      3799 non-null   float64\n",
      " 16  STL      3799 non-null   float64\n",
      " 17  BLK      3799 non-null   float64\n",
      " 18  TOV      3799 non-null   float64\n",
      "dtypes: float64(19)\n",
      "memory usage: 564.0 KB\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('../data/raw/test.csv')\n",
    "df_cleaned = df_test.copy()\n",
    "df_cleaned = dataprep.remove_invalid_rows(df_cleaned, ['GP','FT%'])\n",
    "X_test = df_cleaned.copy()\n",
    "X_test = dataprep.drop_features(X_test, ['Id'])\n",
    "X_test = dataprep.scale_features(X_test, MinMaxScaler(), None)\n",
    "X_test.info()\n",
    "test_probs = clf2.predict_proba(X_test)[:, 1]\n",
    "df_kaggle = pd.DataFrame({'Id': df_cleaned['Id'], 'TARGET_5Yrs': test_probs});\n",
    "df_kaggle.shape\n",
    "df_kaggle.to_csv(\"../data/external/williams_sean-week2_xgboost-v1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9865a9a-88be-472e-b08d-fc70244e6c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
